{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY=\"sk-iMnpLhkPggWL4n1GCSNIfHcx8nGwkaAsKJ4zGjf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = OPENAI_KEY\n",
    "completion = openai.Completion()\n",
    "logs = open(\"chat.log\", \"r\")\n",
    "auto_threshold = 0\n",
    "global_chat_log = logs.read()\n",
    "start_chat_log = '''Human: Hello, who are you?\n",
    "AI: I am doing great. How can I help you today?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_append(log):\n",
    "    with open(\"chat.log\", \"a\") as myfile:\n",
    "        myfile.write(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question, chat_log=None):\n",
    "    if chat_log is None:\n",
    "        chat_log = start_chat_log\n",
    "    chat_log = (chat_log[:1000] + '..') if len(chat_log) > 1000 else chat_log\n",
    "    prompt = f'{chat_log}Human: {question}\\nAI:'\n",
    "    response = completion.create(\n",
    "        prompt=prompt, engine=\"davinci\", stop=['\\nHuman'], temperature=0.9,\n",
    "        top_p=1, frequency_penalty=0, presence_penalty=0.6, best_of=1,\n",
    "        max_tokens=150)\n",
    "    answer = response.choices[0].text.strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_interaction_to_chat_log(question, answer, chat_log=None):\n",
    "    if chat_log is None:\n",
    "        chat_log = start_chat_log\n",
    "    log_append(f'Human: {question}\\nAI: {answer}\\n')\n",
    "    return f'{chat_log}Human: {question}\\nAI: {answer}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_grabber(AI=0, question=None, auto=False, threshold=0):\n",
    "    global global_chat_log\n",
    "    global auto_threshold\n",
    "    \n",
    "    if AI == 0:\n",
    "        question = input()\n",
    "    \n",
    "    answer = ask(f'{question}?', global_chat_log)\n",
    "    global_chat_log = append_interaction_to_chat_log(question, answer, global_chat_log)\n",
    "    \n",
    "    print(answer)\n",
    "    \n",
    "    if auto == True and auto_threshold <= threshold: \n",
    "        auto_threshold += 1\n",
    "        input_grabber(1, answer, True, threshold)\n",
    "    else: \n",
    "        auto_threshold = 0\n",
    "        input_grabber(0, None, False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_chat_log)\n",
    "print(\"Do you want to use auto mode? (Enter number of your choice)\\n1-Yes | 2-No\")\n",
    "auto_mode = input()\n",
    "if auto_mode == 'Yes':\n",
    "    print(\"Enter auto threshold (Default=5)\")\n",
    "    threshold_input = input()\n",
    "    input_grabber(0, None, auto_mode, threshold_input)\n",
    "else:\n",
    "    input_grabber(0, None, False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
